{"cells":[{"cell_type":"markdown","metadata":{"id":"ZXZZyxweQSiu"},"source":["Import"]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"FZWaxvFnpXNZ"}},{"cell_type":"markdown","source":["#HOG"],"metadata":{"id":"BqIAbhhDpXmL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11428,"status":"ok","timestamp":1717535408415,"user":{"displayName":"Michal Polak Szarkowicz","userId":"05632792580948638653"},"user_tz":-60},"id":"ysaT23knVLnw","outputId":"1925e5b9-33ff-4451-cd39-f970925bf93e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.3.0+cu121)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz) (12.5.40)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n"]}],"source":["!pip install torchviz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFCZtuVBQJ_q"},"outputs":[],"source":["from torchvision import datasets, transforms\n","import numpy as np\n","from torchviz import make_dot\n","from IPython.display import Image\n","import os\n","import torch\n","import pandas as pd\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from tqdm import tqdm\n","import time\n","from datetime import datetime\n","import torchvision.models as models\n","import torchvision.models as tv_models\n","from torchvision.models import ResNet18_Weights, MobileNet_V2_Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I2hFbEOao2cr"},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_paths = []\n","        self.labels = []\n","        self.classes = ['diamond', 'squiggle', 'oval']\n","        self._prepare_dataset()\n","\n","    def _prepare_dataset(self):\n","        for root, _, files in os.walk(self.root_dir):\n","            for file in files:\n","                if file.endswith(('.jpg', '.jpeg', '.png')):\n","                    self.image_paths.append(os.path.join(root, file))\n","                    # Extract labels from the directory structure\n","                    parts = root.split(os.sep)\n","                    shape = parts[-1]\n","                    shape_label = self.classes.index(shape)\n","                    self.labels.append(shape_label)\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert(\"RGB\")  # Convert image to RGB\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)  # Apply transformations\n","        return image, torch.tensor(label)"]},{"cell_type":"markdown","metadata":{"id":"feYUJZTzQXNz"},"source":["Step 2: Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aV_lElcQRTg"},"outputs":[],"source":["# Define transformations for the training, validation, and test sets\n","transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","\n","# Create datasets and dataloaders\n","dir_data = './drive/MyDrive/set_data/dataset_shape'\n","train_dataset = CustomImageDataset(root_dir=f\"{dir_data}/train\", transform=transform)\n","valid_dataset = CustomImageDataset(root_dir=f\"{dir_data}/valid\", transform=transform)\n","test_dataset = CustomImageDataset(root_dir=f\"{dir_data}/test\", transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umvbmPWIo_kb"},"outputs":[],"source":["# Visualization function\n","def show_transformed_images(dataset, num_images=5):\n","    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n","    for i in range(num_images):\n","        image, label = dataset[i]\n","        image = image.permute(1, 2, 0)  # Change from CxHxW to HxWxC for visualization\n","        image = (image * 0.5) + 0.5  # Unnormalize the image\n","\n","        axes[i].imshow(image)\n","        axes[i].set_title(f\"Label: {label.item()}\")\n","        axes[i].axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RaEEaAeB3h6D"},"outputs":[],"source":["# Model definition\n","class SimplestCNN(nn.Module):\n","    def __init__(self):\n","        super(SimplestCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","\n","        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 3)  # 3 shape classes: diamond, squiggle, oval\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = x.view(-1, 128 * 8 * 8)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlXmXdPFtxSe"},"outputs":[],"source":["# Define the model classes\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","\n","        self.fc1 = nn.Linear(256 * 4 * 4, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 3)  # 3 classes: diamond, squiggle, oval\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = self.pool(F.relu(self.conv4(x)))\n","        x = x.view(-1, 256 * 4 * 4)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FR0Rd7bBt3op"},"outputs":[],"source":["class VGG(nn.Module):\n","    def __init__(self):\n","        super(VGG, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 2 * 2, 4096),  # Adjusted input size\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 3),  # 3 classes: diamond, squiggle, oval\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms3zaCxct6lu"},"outputs":[],"source":["class ResNet18(nn.Module):\n","    def __init__(self, num_classes=3):\n","        super(ResNet18, self).__init__()\n","        self.model = tv_models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n","        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n","\n","    def forward(self, x):\n","        return self.model(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J-ZqolN9t8VD"},"outputs":[],"source":["class MobileNetV2(nn.Module):\n","    def __init__(self, num_classes=3):\n","        super(MobileNetV2, self).__init__()\n","        self.model = tv_models.mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n","        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, num_classes)\n","\n","    def forward(self, x):\n","        return self.model(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y8Pj5B_LuO4g"},"outputs":[],"source":["def save_model(model, model_name):\n","  print(f\"Saving model: {model_name}\")\n","  now = datetime.now()\n","\n","  # Format the date and time as \"YYYY-MM-DD:HH:MM\"\n","  formatted_now = now.strftime(\"%Y-%m-%d:%H:%M\")\n","  save_dir = \"./drive/MyDrive/Colab NoteBooks Training/models\"\n","  torch.save(model, f\"{save_dir}/{model_name}_{formatted_now}.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KV9xy0SWvPqF"},"outputs":[],"source":["def save_visualization(model, model_name, size=(1,3,64,64)):\n","  print(f\"Saving model visualization: {model_name}\")\n","\n","  sample_input = torch.randn(1, 3, 64, 64)  # 1 sample, 3 channels, 64x64 pixels\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","  inputs = sample_input.to(device)\n","  # Perform a forward pass through the model to create the computational graph\n","  output = model(inputs)\n","\n","  # Visualize the model using torchviz\n","  dot = make_dot(output, params=dict(model.named_parameters()))\n","\n","  # Save and display the visualization\n","  dot.format = 'png'\n","  save_dir = \"./drive/MyDrive/Colab NoteBooks Training/visualizations\"\n","  dot.render(f'{save_dir}/visualization_{model_name}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"neUZP5EwuJZ9"},"outputs":[],"source":["def train(model, train_loader, valid_loader, criterion, optimizer, num_epochs=12):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    print(\"Starting training\")\n","    start_time = time.time()\n","\n","    for epoch in range(num_epochs):\n","        epoch_start_time = time.time()\n","        running_loss = 0.0\n","        model.train()\n","\n","        # Training loop\n","        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        train_duration = time.time() - epoch_start_time\n","        print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}, Time: {train_duration:.2f} seconds\")\n","\n","        # Validation loop\n","        model.eval()\n","        valid_loss = 0.0\n","        correct = 0\n","        total = 0\n","        valid_start_time = time.time()\n","\n","        with torch.no_grad():\n","            for inputs, labels in valid_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                valid_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        valid_duration = time.time() - valid_start_time\n","        accuracy = 100 * correct / total\n","        print(f\"Epoch {epoch+1}, Validation Loss: {valid_loss/len(valid_loader)}, Accuracy: {accuracy:.2f}%, Time: {valid_duration:.2f} seconds\")\n","\n","    total_time = time.time() - start_time\n","    print(f\"Training completed in {total_time:.2f} seconds\")\n","    return model\n","\n","def evaluate(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    test_start_time = time.time()\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    test_duration = time.time() - test_start_time\n","    accuracy = 100 * correct / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%, Time: {test_duration:.2f} seconds\")\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqf286ia43Sm"},"outputs":[],"source":["# Define the models\n","# 'VGG': VGG(),\n","# 'ResNet18': ResNet18(num_classes=3),\n","# 'MobileNetV2': MobileNetV2(num_classes=3)\n","\n","models = {\n","    'SimpleCNN': SimpleCNN()\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KgfAc5jYxsT9"},"outputs":[],"source":["# Train and evaluate each model\n","best_accuracy = 0\n","best_model_name = ''\n","best_model = None\n","print(device)\n","\n","for model_name, model in models.items():\n","    # save_visualization(model, model_name)\n","    print(f'Training {model_name}')\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","    # Train the model\n","    model = train(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10)\n","\n","    # Evaluate the model\n","    accuracy = evaluate(model, test_loader)\n","    save_model(model, f'{model_name}_acc-{accuracy:.2f}')\n","\n","    # Save the model if it has the best accuracy so far\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        best_model_name = model_name\n","        best_model = model\n","        save_model(best_model, f'best_model_{best_model_name}')\n","\n","\n","print(f'Best model: {best_model_name} with accuracy {best_accuracy}%')"]},{"cell_type":"markdown","metadata":{"id":"dqEpOnrK8luu"},"source":["END"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9GHsNSKHVBC","outputId":"17a0c458-4fae-4022-b0c0-0a4d06a6afce","executionInfo":{"status":"ok","timestamp":1717536244327,"user_tz":-60,"elapsed":773919,"user":{"displayName":"Michal Polak Szarkowicz","userId":"05632792580948638653"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:04<00:00, 120MB/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Training Loss: 0.2174252615788226\n","Epoch 1, Validation Loss: 0.000305885171258069, Accuracy: 100.0%\n","Epoch 2, Training Loss: 0.011647151071464088\n","Epoch 2, Validation Loss: 0.07979410262578307, Accuracy: 97.95918367346938%\n","Epoch 3, Training Loss: 0.01498111349636789\n","Epoch 3, Validation Loss: 0.00015428419196394927, Accuracy: 100.0%\n","Epoch 4, Training Loss: 0.0001810904387680851\n","Epoch 4, Validation Loss: 8.353677094508072e-07, Accuracy: 100.0%\n","Epoch 5, Training Loss: 6.794209096319456e-05\n","Epoch 5, Validation Loss: 3.608853139852597e-06, Accuracy: 100.0%\n","Epoch 6, Training Loss: 2.030450313073883e-05\n","Epoch 6, Validation Loss: 1.625484102180108e-06, Accuracy: 100.0%\n","Epoch 7, Training Loss: 1.6695858585905696e-05\n","Epoch 7, Validation Loss: 3.254870808433452e-07, Accuracy: 100.0%\n","Epoch 8, Training Loss: 2.5393872257759235e-05\n","Epoch 8, Validation Loss: 2.9010030261344966e-07, Accuracy: 100.0%\n","Epoch 9, Training Loss: 6.321610009394864e-07\n","Epoch 9, Validation Loss: 1.462168266463948e-07, Accuracy: 100.0%\n","Epoch 10, Training Loss: 0.019167074812910963\n","Epoch 10, Validation Loss: 0.0010211631682874867, Accuracy: 100.0%\n","Epoch 11, Training Loss: 0.11438453068282464\n","Epoch 11, Validation Loss: 4.388340856868247, Accuracy: 68.57142857142857%\n","Epoch 12, Training Loss: 0.3478541943564131\n","Epoch 12, Validation Loss: 0.0022295475884392957, Accuracy: 100.0%\n","Epoch 13, Training Loss: 0.04819128572489717\n","Epoch 13, Validation Loss: 0.0010158987046509083, Accuracy: 100.0%\n","Epoch 14, Training Loss: 0.0020931696254382795\n","Epoch 14, Validation Loss: 5.069383419709084e-05, Accuracy: 100.0%\n","Epoch 15, Training Loss: 0.00013530985042109478\n","Epoch 15, Validation Loss: 1.5455534821295913e-05, Accuracy: 100.0%\n","Epoch 16, Training Loss: 0.00012640634609340805\n","Epoch 16, Validation Loss: 3.3151573965994885e-06, Accuracy: 100.0%\n","Epoch 17, Training Loss: 8.159896153223314e-06\n","Epoch 17, Validation Loss: 1.8066856755094562e-06, Accuracy: 100.0%\n","Epoch 18, Training Loss: 5.51212105217153e-05\n","Epoch 18, Validation Loss: 1.7759613632151172e-05, Accuracy: 100.0%\n","Epoch 19, Training Loss: 3.5627935812516835e-06\n","Epoch 19, Validation Loss: 3.1012625711923647e-07, Accuracy: 100.0%\n","Epoch 20, Training Loss: 3.2929453270739236e-06\n","Epoch 20, Validation Loss: 7.222259894301697e-07, Accuracy: 100.0%\n","Test Accuracy: 100.0%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","from torchvision.models import VGG16_Weights\n","\n","# Define transformations with data augmentation\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Load datasets\n","data_dir = './drive/MyDrive/set_data/dataset_shape'\n","train_dataset = ImageFolder(f'{data_dir}/train', transform=transform)\n","valid_dataset = ImageFolder(f'{data_dir}/valid', transform=transform)\n","test_dataset = ImageFolder(f'{data_dir}/test', transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Load pretrained VGG model and modify the final layer\n","model = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n","num_features = model.classifier[6].in_features\n","model.classifier[6] = nn.Linear(num_features, 3)  # 3 classes: diamond, squiggle, oval\n","\n","# Define loss and optimizer with a smaller learning rate\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","# Train the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","def train(model, train_loader, valid_loader, criterion, optimizer, num_epochs=20):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        print(f'Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}')\n","\n","        # Validation step\n","        model.eval()\n","        valid_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in valid_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                valid_loss += loss.item()\n","                _, predicted = torch.max(outputs, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        accuracy = 100 * correct / total\n","        print(f'Epoch {epoch+1}, Validation Loss: {valid_loss/len(valid_loader)}, Accuracy: {accuracy}%')\n","\n","train(model, train_loader, valid_loader, criterion, optimizer, num_epochs=20)\n","\n","# Evaluate the model\n","def evaluate(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f'Test Accuracy: {accuracy}%')\n","\n","evaluate(model, test_loader)\n"]},{"cell_type":"code","source":["from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt\n","\n","# !rm -rf ./logs/\n","\n","writer = SummaryWriter(log_dir=\"./runs/set\")\n","\n","examples = iter(test_loader)\n","example_data, example_targets = examples.next()\n","\n","for i in range(6):\n","  plt.subplot(2,3, i+1)\n","  plt.imshow(example_data[i][0], cmap='gray')\n","img_grid = torchvision.utils.make_grid(example_data)\n","writer.add_image(\"set_images\", img_grid)"],"metadata":{"id":"3kmevwNABbrz","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1717536248985,"user_tz":-60,"elapsed":4659,"user":{"displayName":"Michal Polak Szarkowicz","userId":"05632792580948638653"}},"outputId":"f9e15c6e-b010-48ff-d825-21205b010311"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'_SingleProcessDataLoaderIter' object has no attribute 'next'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-f9fb566ff643>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mF8pWWYlH_zq"},"outputs":[],"source":["save_model(model, \"vgg16\")\n","save_visualization(model, 'vgg16', (1, 3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_TTsXfhepMdE"},"outputs":[],"source":["\n","# # Training function with validation\n","# def train(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10):\n","#     print(\"Starting training\")\n","#     start_time = time.time()\n","\n","#     for epoch in range(num_epochs):\n","#         epoch_start_time = time.time()\n","#         running_loss = 0.0\n","#         model.train()\n","\n","#         # Training loop\n","#         for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n","#             inputs, labels = inputs.to(device), labels.to(device)\n","#             optimizer.zero_grad()\n","#             outputs = model(inputs)\n","#             loss = criterion(outputs, labels)\n","#             loss.backward()\n","#             optimizer.step()\n","#             running_loss += loss.item()\n","\n","#         train_duration = time.time() - epoch_start_time\n","#         print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}, Time: {train_duration:.2f} seconds\")\n","\n","#         # Validation loop\n","#         model.eval()\n","#         valid_loss = 0.0\n","#         correct = 0\n","#         total = 0\n","#         valid_start_time = time.time()\n","\n","#         with torch.no_grad():\n","#             for inputs, labels in valid_loader:\n","#                 inputs, labels = inputs.to(device), labels.to(device)\n","#                 outputs = model(inputs)\n","#                 loss = criterion(outputs, labels)\n","#                 valid_loss += loss.item()\n","\n","#                 _, predicted = torch.max(outputs.data, 1)\n","#                 total += labels.size(0)\n","#                 correct += (predicted == labels).sum().item()\n","\n","#         valid_duration = time.time() - valid_start_time\n","#         accuracy = 100 * correct / total\n","#         print(f\"Epoch {epoch+1}, Validation Loss: {valid_loss/len(valid_loader)}, Accuracy: {accuracy:.2f}%, Time: {valid_duration:.2f} seconds\")\n","\n","#     total_time = time.time() - start_time\n","#     print(f\"Training completed in {total_time:.2f} seconds\")\n","\n","# def evaluate(model, test_loader):\n","#     model.eval()\n","#     correct = 0\n","#     total = 0\n","#     test_start_time = time.time()\n","\n","#     with torch.no_grad():\n","#         for inputs, labels in test_loader:\n","#             inputs, labels = inputs.to(device), labels.to(device)\n","#             outputs = model(inputs)\n","#             _, predicted = torch.max(outputs.data, 1)\n","#             total += labels.size(0)\n","#             correct += (predicted == labels).sum().item()\n","\n","#     test_duration = time.time() - test_start_time\n","#     accuracy = 100 * correct / total\n","#     print(f\"Test Accuracy: {accuracy:.2f}%, Time: {test_duration:.2f} seconds\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CHoiE6ApOOn"},"outputs":[],"source":["# train(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B6jLD9pNpTMN"},"outputs":[],"source":["# # Evaluate the model\n","# evaluate(model, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"W5HbntZgQWWW"},"source":["Step 3: Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1OYBxgzQdxW"},"outputs":[],"source":["# class CardClassifierCNN(nn.Module):\n","#     def __init__(self):\n","#         super(CardClassifierCNN, self).__init__()\n","#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","#         self.fc1 = nn.Linear(128 * 8 * 8, 256)\n","#         self.fc2 = nn.Linear(256, 64)\n","#         self.fc3 = nn.Linear(64, 3)\n","\n","#     def forward(self, x):\n","#         x = self.pool(F.relu(self.conv1(x)))\n","#         x = self.pool(F.relu(self.conv2(x)))\n","#         x = self.pool(F.relu(self.conv3(x)))\n","#         x = x.view(-1, 128 * 8 * 8)\n","#         x = F.relu(self.fc1(x))\n","#         x = F.relu(self.fc2(x))\n","#         x = self.fc3(x)\n","#         return x\n","\n","# # Initialize the model, loss function and optimizer\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# print(f\"Using device: {device}\")\n","\n","\n","# model = CardClassifierCNN().to(device)\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(model.parameters(), lr=0.001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDqlKqxoTRia"},"outputs":[],"source":["# # Perform a sample input tensor with the shape (batch_size, channels, height, width)\n","\n","# def save_model_vis(model, model_name):\n","#   sample_input = torch.randn(1, 3, 64, 64)  # 1 sample, 3 channels, 64x64 pixels\n","\n","\n","#   inputs = sample_input.to(device)\n","#   # Perform a forward pass through the model to create the computational graph\n","#   output = model(inputs)\n","# #\n","#   # Visualize the model using torchviz\n","#   dot = make_dot(output, params=dict(model.named_parameters()))\n","\n","#   # Save and display the visualization\n","#   dot.format = 'png'\n","\n","#   dot.render(f'model_visualization_{model_name}')\n","\n","# # To display the image inline (if using a Jupyter notebook or similar environment)\n","# # Image(filename='model_visualization.png')"]},{"cell_type":"markdown","metadata":{"id":"VhLyJty7Qgt-"},"source":["Step 4: Training and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PnTzQOy_QiIG"},"outputs":[],"source":["# import time\n","\n","# def train(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10):\n","#     print(\"Starting training\")\n","#     start_time = time.time()\n","\n","#     model.train()\n","#     train_initialization_end = time.time()\n","\n","#     print(f\"Finished Training Initialization - {train_initialization_end - start_time:.2f}\")\n","\n","#     print(\"Beginning Epochs\")\n","#     for epoch in range(num_epochs):\n","#         epoch_start_time = time.time()\n","#         running_loss = 0.0\n","#         train_start_time = time.time()\n","\n","#         # Using tqdm to visualize the training progress\n","#         for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n","#             inputs, labels = inputs.to(device), labels.to(device)\n","#             optimizer.zero_grad()\n","#             outputs = model(inputs) # resets\n","#             loss = criterion(outputs, labels)\n","#             loss.backward()\n","#             optimizer.step()\n","#             running_loss += loss.item()\n","\n","#         train_end_time = time.time()\n","#         train_duration = train_end_time - train_start_time\n","#         print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}, Time: {train_duration:.2f} seconds\")\n","\n","#         # Validate the model\n","#         model.eval()\n","#         valid_loss = 0.0\n","#         correct = 0\n","#         total = 0\n","#         valid_start_time = time.time()\n","\n","#         with torch.no_grad():\n","#             for inputs, labels in valid_loader:\n","#                 inputs, labels = inputs.to(device), labels.to(device)\n","#                 outputs = model(inputs)\n","#                 loss = criterion(outputs, labels)\n","#                 valid_loss += loss.item()\n","#                 _, predicted = torch.max(outputs.data, 1)\n","#                 total += labels.size(0)\n","#                 correct += (predicted == labels).sum().item()\n","\n","#         valid_end_time = time.time()\n","#         valid_duration = valid_end_time - valid_start_time\n","#         accuracy = 100 * correct / total\n","#         print(f\"Epoch {epoch+1}, Validation Loss: {valid_loss/len(valid_loader)}, Accuracy: {accuracy:.2f}%, Time: {valid_duration:.2f} seconds\")\n","\n","#         model.train()\n","#         epoch_end_time = time.time()\n","#         epoch_duration = epoch_end_time - epoch_start_time\n","#         print(f\"Epoch {epoch+1} completed in {epoch_duration:.2f} seconds\")\n","\n","#     total_time = time.time() - start_time\n","#     print(f\"Training completed in {total_time:.2f} seconds\")\n","\n","# def evaluate(model, test_loader):\n","#     model.eval()\n","#     correct = 0\n","#     total = 0\n","#     test_start_time = time.time()\n","\n","#     with torch.no_grad():\n","#         for inputs, labels in tqdm(test_loader, unit=\"batch\"):\n","#         # for inputs, labels in test_loader:\n","#             inputs, labels = inputs.to(device), labels.to(device)\n","#             outputs = model(inputs)\n","#             _, predicted = torch.max(outputs.data, 1)\n","#             total += labels.size(0)\n","#             correct += (predicted == labels).sum().item()\n","\n","#     test_end_time = time.time()\n","#     test_duration = test_end_time - test_start_time\n","#     accuracy = 100 * correct / total\n","#     print(f\"Test Accuracy: {accuracy:.2f}%, Time: {test_duration:.2f} seconds\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6M5mV2h6U0pa"},"outputs":[],"source":["# # Train the model\n","# train(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fRAJtRJkU4iC"},"outputs":[],"source":["# # Evaluate the model\n","# evaluate(model, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"VKUpnzihVt5t"},"source":["Step 2: Save the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Px4VnrqVuUE"},"outputs":[],"source":["# # Get the current date and time\n","# now = datetime.now()\n","\n","# # Format the date and time as \"YYYY-MM-DD:HH:MM\"\n","# formatted_now = now.strftime(\"%Y-%m-%d:%H:%M\")\n","# save_dir = \"./drive/MyDrive/Colab NoteBooks\"\n","# torch.save(model, f\"{save_dir}/card_classifier_model_{formatted_now}.pth\")"]},{"cell_type":"markdown","metadata":{"id":"DkkXQauGV0UG"},"source":["Step 3: Load the Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGn4Bt2sVumq"},"outputs":[],"source":["# # Load the entire model\n","# loaded_model = torch.load('./card_classifier_model.pth', map_location=torch.device('cpu'))\n","# loaded_model.eval()  # Set the model to evaluation mode"]},{"cell_type":"markdown","metadata":{"id":"LrIGruQ6V4Tv"},"source":["Step 4: Use the Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K546SQYIV5H1"},"outputs":[],"source":["# from PIL import Image\n","# from torchvision import transforms\n","\n","# # Define the transformations (same as during training)\n","# transform = transforms.Compose([\n","#     transforms.Resize((64, 64)),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","# ])\n","\n","# # Load an example image\n","# image = Image.open('1PSO.jpg')\n","\n","# # Transform the image\n","# image = transform(image)\n","# image = image.unsqueeze(0)  # Add a batch dimension\n","\n","# # Make a prediction\n","# output = loaded_model(image)\n","# _, predicted_class = torch.max(output.data, 1)\n","\n","# # Print the predicted class\n","# class_names = ['oval', 'squiggle', 'diamond']\n","# print(f'Predicted class: {class_names[predicted_class]}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEdRF9zCuhVs"},"outputs":[],"source":["# from PIL import Image\n","# from torchvision import transforms\n","\n","# # Define the transformations (same as during training)\n","# transform = transforms.Compose([\n","#     transforms.Resize((64, 64)),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","# ])\n","\n","# def classify_image(model, image_path, transform):\n","#     model.eval()\n","#     image = Image.open(image_path)\n","#     image = transform(image)\n","#     image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n","\n","#     with torch.no_grad():\n","#         output = model(image)\n","#         _, predicted = torch.max(output.data, 1)\n","\n","#     class_names = train_dataset.classes  # Assuming classes are in the same order as in dataset folders\n","#     return class_names[predicted.item()]\n","\n","# # Example usage\n","\n","# image_path = './1GSS_0f212ca0-605c-4e50-add6-feb89e833c77.jpg'\n","# predicted_class = classify_image(loaded_model, image_path, transform)\n","# print(f'The predicted class for the image is: {predicted_class}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WD1q97la1ray"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","\n","# def show_transformed_images(dataset, num_images=20):\n","#     fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n","#     for i in range(num_images):\n","#         image, labels = dataset[i]\n","#         image = image.permute(1, 2, 0)  # Change from CxHxW to HxWxC for visualization\n","#         image = (image * 0.5) + 0.5  # Unnormalize the image\n","\n","#         axes[i].imshow(image)\n","#         axes[i].set_title(f\"{labels}\")\n","#         axes[i].axis('off')\n","#     plt.show()\n","\n","# # Example usage\n","# show_transformed_images(valid_dataset)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"11K1tXKyhmdoFTaq74P12e6Eu8PNwB5-1","authorship_tag":"ABX9TyNXnluv1AwbRnPIYH+YVybJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}